{
  "config": {
    "dataset_name": "rotten_tomatoes",
    "model_name": "roberta-base",
    "max_length": 128,
    "num_labels": 2,
    "num_epochs": 3,
    "batch_size": 16,
    "learning_rate_full": 2e-05,
    "learning_rate_lora": 0.0001,
    "lora_rank": 8,
    "lora_alpha_ratio": 2,
    "description": "Quick experiment: Rotten Tomatoes + RoBERTa-base"
  },
  "full_finetuning": {
    "experiment_name": "Full Fine-Tuning",
    "training_time": 102.24158596992493,
    "train_loss": 0.28626146923736684,
    "eval_loss": 0.47083166241645813,
    "eval_accuracy": 0.8921200750469043,
    "total_params": 124647170,
    "trainable_params": 124647170,
    "trainable_percentage": 100.0
  },
  "lora": {
    "experiment_name": "LoRA Fine-Tuning",
    "training_time": 75.24987816810608,
    "train_loss": 0.33420405584328183,
    "eval_loss": 0.31564420461654663,
    "eval_accuracy": 0.8808630393996247,
    "total_params": 126248795,
    "trainable_params": 1603163,
    "trainable_percentage": 1.269844199305031
  },
  "comparison": {
    "speedup": 1.358694372122705,
    "param_reduction": 77.75077768137113,
    "accuracy_diff": -0.011257035647279534,
    "accuracy_retention_pct": 98.73817034700315
  }
}